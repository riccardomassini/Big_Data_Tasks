**TASK2c: Leggere i paper caricati su elearning e riassumerli max 5 righe/cad, evidenziandone gli aspetti di analisi dati**

RIASSUNTO 1 :
Il primo articolo parla della raccolta di grandi quantità di dati in grandi città, in particolar modo su una raccolta di dati nella città di Milano. Questo metodo ha permesso di raccogliere grandi quantità di dati in maniera passiva ( senza strumentazione dedicata come sensori ) grazie ai cellulari. Questo metodo ha permesso di capire che i dati che possiamo raccogliere con i nostri cellulari sono di un accuratezza superiore a quella che raccoglievamo con i sistemi precedenti come GPS e social media. Questo esperimento su questa tecnologia ci fa dare uno sguardo sui suoi possibili utilizzi futuri, come per esempio per l'ottimizzazione del traffico e dei metodi trasporto.

RIASSUNTO 2 : questo articolo parla dell'uso di modelli di Machine Learning per prevedere e analizzare la qualità del vino e dell'olio d'oliva. Lo studio ha analizzato 3 dataset di dati reali su 3 modelli di Machine Learning : il risultato ha dato risultati estremamente positivi sulle origini (sia del vino che dell'olio ), e un po meno soddisfacenti sulla qualità del vino. Da questa ricerca è stato sviluppato anche un tool AI, che ci lancia sempre di più verso un futuro in cui questi sistemi e ricerche possano diventare uno standard normale per garantire qualità.

RIASSUNTO 3 : Il terzo articolo tratta del traffico urbano e di come possa essere migliorata la sua gestione in termini di inquinamento e fluidità. L'articolo si concentra tanto sul concetto del semaforo, spiegado in primo luogo come funziona oggi giorno e di come domani, tramite tecnologie come il Reinforcement Learning o il Deep Q-Learning, possa imparare man mano l'andamento del traffico e ottimizzarsi. Il Deep Q-Learning permetterà ai semafori di analizzare lo stato del traffico, aumentare/ridurre le fasi del semaforo e quindi così ottimizzare il traffico. Confrontando il modello di DQL con gli altri sistemim ( cicli fissi, attuale ecc ) è risultati nettamente il migliore, dando così conferma che questa potrà essere ciò che verrà implementato nel futuro.

RIASSUNTO 4 : Il quarto articolo parla dell'uso dell'intelligenza artificiale nella politica. In particolar modo si concentra su un modello di chatbot AI chaimato Epizzul, il quale simula una conversazione tra candidatore ed elettore, andando quindi a simulare le risposte possibile che da un candidato mantendendo il suo tono, stile ecc. Esso è stato sviluppato utilizzando GPT 3.5 e GPT 4 : su GPT 3.5 il chatbot non aveva abbastanza personalità e si adattava troppo all'utente, mentre nela versiona su GPT 4 manteneva uno schema più rigido rispettando le idee del candito che aveva e dava risposte più precise/accurate. Questo studio però ci deve anche riflettere sui futuri possibili utilizzi dell'AI in politica, questo perchè si è già dimostratouno strumento potente, che un domani potrà portare manipolazione, disinformazione e una mancanza di trasparenza generale.